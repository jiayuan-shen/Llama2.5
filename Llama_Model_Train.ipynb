{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNj+awyKEETuD5rgvbKSEu2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ea6d704c7c0d45e7b3aa0b39fd35fba5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc6fd998c9114c23a051d8979798ad61","IPY_MODEL_58a68fa066f741efbf38a9345cf6f1d2","IPY_MODEL_10ca9f8d6a114d78a04022db9a3ec12b"],"layout":"IPY_MODEL_85434f0f9bc2487ea4e0654c583bbca4"}},"bc6fd998c9114c23a051d8979798ad61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d194426bdd7c4cd08540ae820b6e5829","placeholder":"​","style":"IPY_MODEL_3451ee7fa4c7477aa544974504cd8952","value":"testing batch:   0%"}},"58a68fa066f741efbf38a9345cf6f1d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eca2ff49ec246f5a003dfacbff4bee0","max":9800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82c02d1f864242f2b7f892df0ef1e03c","value":0}},"10ca9f8d6a114d78a04022db9a3ec12b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ca55b325b2c49849ffba44bcfbefa25","placeholder":"​","style":"IPY_MODEL_b78a9bae978142108aa5393c3c823990","value":" 0/9800 [00:00&lt;?, ?it/s]"}},"85434f0f9bc2487ea4e0654c583bbca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d194426bdd7c4cd08540ae820b6e5829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3451ee7fa4c7477aa544974504cd8952":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1eca2ff49ec246f5a003dfacbff4bee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82c02d1f864242f2b7f892df0ef1e03c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ca55b325b2c49849ffba44bcfbefa25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b78a9bae978142108aa5393c3c823990":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ULNtfDnzAge","executionInfo":{"status":"ok","timestamp":1723248398215,"user_tz":240,"elapsed":21599,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"outputId":"aad36f1b-544d-4ffb-c5f0-6656515823ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.7.4)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"]}],"source":["! pip install datasets\n","! pip install transformers\n","! pip install huggingface_hub\n","! pip install evaluate"]},{"cell_type":"markdown","source":["# Import Essential Libraries"],"metadata":{"id":"opIXNLAPzt3r"}},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import AdamW, lr_scheduler\n","from torch.cuda.amp import GradScaler, autocast\n","from transformers import AutoTokenizer\n","from datasets import load_dataset\n","from tqdm.auto import tqdm\n","from torch.nn.utils.rnn import pad_sequence\n","import evaluate"],"metadata":{"id":"-A_0cHJuztuP","executionInfo":{"status":"ok","timestamp":1723248413164,"user_tz":240,"elapsed":14952,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Init the Hyperparameter"],"metadata":{"id":"zTmvYn0WTiKT"}},{"cell_type":"code","source":["MASTER_CONFIG = {\n","    \"vocab_size\": 30592, # 30526 + 1\n","    \"num_epochs\":12,\n","    \"batch_size\": 8,\n","    \"num_epochs\": 12,\n","    \"d_model\": 2048,\n","    \"nhead\": 8,\n","    \"n_q_head\": 16,\n","    \"n_kv_head\": 8,\n","    \"dim_feedforward\": 2048,\n","    \"num_layers\": 12,\n","    \"learning_rate\": 3e-4,\n","    \"max_seq_len\": 1024,\n","    \"device\": 'cuda' if torch.cuda.is_available() else 'cpu'\n","}\n","device = MASTER_CONFIG['device']\n","from google.colab import drive\n","drive.mount('/content/drive')\n","llama_path = '/content/drive/MyDrive/MSML612/Final Project/Llama'"],"metadata":{"id":"seFVA5BGTkb9","executionInfo":{"status":"ok","timestamp":1723248414039,"user_tz":240,"elapsed":878,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"38483d88-ecf2-45b3-d862-625a7dc23ce3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Load and Preprocess the Dataset"],"metadata":{"id":"S1lOSNBFzkr0"}},{"cell_type":"code","source":["# Load the dataset\n","datasets = load_dataset('Wodeyuanbukongda/SQuard_Chatbot_Llama')"],"metadata":{"id":"vZjQ1fb6zf6Y","executionInfo":{"status":"ok","timestamp":1723248416471,"user_tz":240,"elapsed":2436,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a24f9c3c-b53c-41e0-ae4e-618629441eac"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Init the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n","tokenizer.add_special_tokens({'bos_token': '[BOS]'})\n","tokenizer.add_special_tokens({'eos_token': '[EOS]'})\n","tokenizer.add_special_tokens({'additional_special_tokens': ['[CON]', '[QUE]', '[ANS]']})\n","\n","# Check the tokenizer\n","print(tokenizer.special_tokens_map)\n","print(tokenizer.all_special_ids)\n","\n","# Split the dataset after preprocessing\n","datasets = datasets['train'].train_test_split(test_size=0.1)\n","\n","# Check the structure\n","print(datasets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw_-ptmH2tYi","executionInfo":{"status":"ok","timestamp":1723248416750,"user_tz":240,"elapsed":282,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"outputId":"6f85c4f8-5530-422c-ae73-7476e897282f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{'bos_token': '[BOS]', 'eos_token': '[EOS]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[CON]', '[QUE]', '[ANS]']}\n","[30522, 30523, 100, 102, 0, 101, 103, 30524, 30525, 30526]\n","DatasetDict({\n","    train: Dataset({\n","        features: ['input', 'output', 'ans_index'],\n","        num_rows: 88191\n","    })\n","    test: Dataset({\n","        features: ['input', 'output', 'ans_index'],\n","        num_rows: 9800\n","    })\n","})\n"]}]},{"cell_type":"markdown","source":["# Dataset class"],"metadata":{"id":"xLSL7ikJJBdb"}},{"cell_type":"code","source":["# Here we do not use batch\n","# Init the dataset class\n","class Squad(Dataset):\n","    def __init__(self, squad):\n","        super().__init__()\n","        self.squad = squad\n","\n","    def __getitem__(self, index):\n","        # Custom the get method\n","        item = self.squad[index]\n","        input = torch.tensor(item['input'])\n","        output = torch.tensor(item['output'])\n","        ans_index = torch.tensor(item['ans_index'])\n","        return {'input': input, 'output': output, 'ans_index': ans_index}\n","\n","    def __len__(self):\n","        # Return the total number of training instances\n","        return len(self.squad)\n","\n","\n","def generate_mask(sequence):\n","    seq_len = len(sequence[0]) # Select one element and acqure the sequence\n","    padding_mask = (sequence == float(tokenizer.pad_token_id))\n","    attention_mask = (torch.tril(torch.ones(seq_len, seq_len)) == 0)\n","    return padding_mask, attention_mask\n","\n","\n","def collate_fn(batch):\n","    # Collate function used to ensure the input have the same sequence lenght (T)\n","    # Assume the input is a batch\n","    input = [item['input'] for item in batch] # [[],[],[]]\n","    output = [item['output'] for item in batch]\n","    ans_index = [item['ans_index'] for item in batch]\n","\n","    # pad_sequence: Pad a list of variable length Tensors with padding_value.\n","    # The resulting Tensor will have shape (B,T)\n","    padded_input_seq = pad_sequence( input, batch_first=True, padding_value=tokenizer.pad_token_id )  # [B,T]\n","    # Generate the mask\n","    padding_mask_input, attention_mask_input = generate_mask(padded_input_seq)\n","\n","\n","    padded_output_seq = pad_sequence(output, batch_first=True, padding_value=tokenizer.pad_token_id)\n","    return {'input': padded_input_seq, 'output': padded_output_seq, 'padding_mask': padding_mask_input,\n","            'attention_mask': attention_mask_input, 'ans_index': ans_index}\n","\n","\n","# Create the dataloader\n","dataset_train = Squad(datasets['train'])\n","dataset_val = Squad(datasets['test'])\n","dataloader_train = DataLoader(dataset_train, batch_size=MASTER_CONFIG['batch_size'],\n","                                  collate_fn = collate_fn, shuffle=True, num_workers=2)\n","dataloader_val = DataLoader(dataset_val, batch_size=1,\n","                                  collate_fn = collate_fn, shuffle=False, num_workers=2)\n","# Check the shape after create the dataloader\n","for i, batch in enumerate(dataloader_train):\n","    print(batch.keys())\n","    print(batch['input'].shape)\n","    print(batch['output'].shape)\n","    print(batch['padding_mask'].shape)\n","    print(batch['attention_mask'].shape)\n","    break"],"metadata":{"id":"05WVCSOYJDjF","executionInfo":{"status":"ok","timestamp":1723248417254,"user_tz":240,"elapsed":505,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"892a9e49-58cc-470d-f25e-2999708f3a2f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["dict_keys(['input', 'output', 'padding_mask', 'attention_mask', 'ans_index'])\n","torch.Size([8, 448])\n","torch.Size([8, 448])\n","torch.Size([8, 448])\n","torch.Size([448, 448])\n"]}]},{"cell_type":"markdown","source":["# Constructe the Model"],"metadata":{"id":"0z5xA1JR8Cko"}},{"cell_type":"code","source":["# Init the word embedding layer\n","class WordEmbedding(nn.Module):\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","\n","    def forward(self, x):\n","        return self.embedding(x)\n","\n","# RMS norm layer\n","class RMSNorm(nn.Module):\n","    def __init__(self, d_model, eps=1e-6):\n","        super().__init__()\n","        self.alpha = nn.Parameter(torch.ones(d_model))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        # x: [B,T,C]\n","        # torch.rsqrt = 1 / sqrt(input)\n","        rms = torch.rsqrt(torch.mean(torch.square(x), dim=-1, keepdim=True) + self.eps)\n","        return self.alpha * rms * x\n","\n","# Rotary Embedding layer\n","class PosEmbedding(nn.Module):\n","    '''\n","    In the context of Llama\n","    We only do the positional encoding for the q, k matrix\n","    However, due to the multiquery attention, q,k matrix does not have the same shape\n","    Furthermore, since the Llama percieve each head as a new query\n","    we do the positional encoding in terms of the head_dim\n","    q.shape = [B, T, H, d//H]\n","    k.shape = [B, T, H_kv, d//H]\n","    '''\n","    # Here d_model is head_dim\n","    def __init__(self, seq_len, d_model):\n","        super().__init__()\n","        # \\theta = 10000^( -2(i-1) / d_model )\n","        # self.theta.shape = [d/2]\n","        self.theta = torch.pow(10000.0, -2 * (torch.arange(1, d_model / 2 + 1) - 1) / d_model)\n","\n","        # Acquire the position\n","        #self.m.shape = [T]\n","        self.m = torch.arange(0, seq_len)\n","\n","        # Acquire the matrix\n","        # torch.outer(self,m, self.theta).shape = [T, d/2] (compute the outer product)\n","        # The result will looks like this:\n","        # [0\\theta_1, 0\\theta_2\n","        #  1\\theta_1, 1\\theta_2\n","        #  2\\theta_1, 2\\theta_2\n","        #  3\\theta_1, 3\\theta_2]\n","\n","        # torch.polar:\n","        # Convert the Cartesian coordinates to polar coordinates\n","        # out = abs * cos(angle) + abs * sin(angle) * j\n","        # abs.shape = [T, d/2]\n","        # angle.shape = [T, d/2]\n","        # self.matrix.shape = [T, d/2]\n","        # self.matrix result will looks like:\n","        # [cos( 0\\theta_1 )+sin( 0\\theta_1 )*j, cos( 0\\theta_2 )+sin( 0\\theta_2 )*j\n","        #  cos( 1\\theta_1 )+sin( 1\\theta_1 )*j, cos( 1\\theta_2 )+sin( 1\\theta_2 )*j\n","        #  ...\n","        #  cos( T\\theta_1 )+sin( T\\theta_1 )*j, cos( T\\theta_2 )+sin( T\\theta_2 )*j]\n","\n","        # Actual output looks like:\n","        # tensor([[ 1.0000+0.0000j,  1.0000+0.0000j],\n","        #         [ 0.5403+0.8415j,  0.9999+0.0100j],\n","        #         [-0.4161+0.9093j,  0.9998+0.0200j],\n","        #         [-0.9900+0.1411j,  0.9996+0.0300j]])\n","        self.matrix = torch.polar(abs=torch.ones_like(torch.outer(self.m, self.theta)),\n","                                  angle=torch.outer(self.m, self.theta))\n","\n","    def forward(self, x):\n","        # x.shape = [B, T, H, d//H] if q\n","        # x.shape = [B, T, H_kv, d//H] if k\n","        B, T, h, C = x.shape\n","\n","        # torch.view_as_complex: Returns a view of input as a complex tensor\n","        # suppose the input is:\n","        # tensor([[ 1.6116, -0.5772],\n","        #         [-1.4606, -0.9120],\n","        #         [ 0.0786, -1.7497],\n","        #         [-0.6561, -1.6623]])\n","        # The output will looks like this:\n","        # tensor([(1.6116-0.5772j), (-1.4606-0.9120j), (0.0786-1.7497j), (-0.6561-1.6623j)])\n","\n","        # [B, T, H, d//H] -> [B, T, H, d//H/2, 2] -> [B, T, H, d//H/2]\n","\n","        # To understand how this code work, I generate a small sample:\n","        # Suppose [B, T, d] is like this: assume B = 1\n","        # tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7],\n","        #         [ 8,  9, 10, 11, 12, 13, 14, 15],\n","        #         [16, 17, 18, 19, 20, 21, 22, 23],\n","        #         [24, 25, 26, 27, 28, 29, 30, 31]]])\n","\n","        # After reshape the [B, T, d] to [B, T, H, d//H] the output like:\n","        # tensor([[[[ 0.,  1.,  2.,  3.],\n","        #           [ 4.,  5.,  6.,  7.]],\n","\n","        #           [[ 8.,  9., 10., 11.],\n","        #           [12., 13., 14., 15.]],\n","\n","        #           [[16., 17., 18., 19.],\n","        #           [20., 21., 22., 23.]],\n","\n","        #           [[24., 25., 26., 27.],\n","        #           [28., 29., 30., 31.]]]]\n","\n","        # Then, we reshape the [B, T, H, d//H] to [B, T, H, d//H/2, 2] the output like:\n","        # tensor([[[[[ 0.,  1.],\n","        #           [ 2.,  3.]],\n","\n","        #           [[ 4.,  5.],\n","        #           [ 6.,  7.]]],\n","\n","\n","        #         [[[ 8.,  9.],\n","        #           [10., 11.]],\n","\n","        #           [[12., 13.],\n","        #           [14., 15.]]],\n","\n","\n","        #         [[[16., 17.],\n","        #           [18., 19.]],\n","\n","        #           [[20., 21.],\n","        #           [22., 23.]]],\n","\n","\n","        #         [[[24., 25.],\n","        #           [26., 27.]],\n","\n","        #           [[28., 29.],\n","        #           [30., 31.]]]]]\n","\n","        # Finally, the x_complex is looks like:\n","        # tensor([[[[ 0.+1.j,  2.+3.j],\n","        #           [ 4.+5.j,  6.+7.j]],\n","\n","        #         [[ 8.+9.j, 10.+11.j],\n","        #           [12.+13.j, 14.+15.j]],\n","\n","        #         [[16.+17.j, 18.+19.j],\n","        #           [20.+21.j, 22.+23.j]],\n","\n","        #         [[24.+25.j, 26.+27.j],\n","        #           [28.+29.j, 30.+31.j]]]]\n","\n","        x_complex = torch.view_as_complex(x.reshape(B, T, h, -1, 2))  # [B,T,h,C/2]\n","\n","        matrix_complex = self.matrix.unsqueeze(0).unsqueeze(2).to(x_complex.device)  # [1,seq_len,1,C/2]\n","        x_out = x_complex * matrix_complex[:, :T, :, :] #[B, T, H, d//H/2]\n","        x_out = torch.view_as_real(x_out).reshape(x.shape)\n","        return x_out\n","\n","# FeedForward layer\n","class FeedForward(nn.Module):\n","  '''\n","  Here the Input x with shape [B, T, d]\n","  Note: in the Llama, we do not have a trainable parameter \\beta\n","  but in the paper, we do have a trainable parameter \\beta\n","  where swish = x * \\sigma( \\beta * x )\n","  '''\n","  def __init__(self, d_model, hidden_dim):\n","      super().__init__()\n","      self.W = nn.Linear(d_model, hidden_dim)\n","      self.W2 = nn.Linear(hidden_dim, d_model)\n","      self.V = nn.Linear(d_model, hidden_dim)\n","\n","  def forward(self, x):\n","      swish = F.silu(self.W(x))\n","      x_v = self.V(x)\n","      return self.W2(swish * x_v)\n","\n","# A independent function\n","def repeat_kv(x, n_rep):\n","  '''\n","  Use to let the k, v matrix have the same shape as the q matrix to fit the attention\n","  q.shape = [B, T, H, d//H]\n","  k.shape = [B, T, H_kv, d//H]\n","  v.shape = [B, T, H_kv, d//H]\n","  n_rep = numbers of times that k,v heads repeat\n","  '''\n","  B, T, n_kv_head, head_dim = x.shape\n","  if n_rep == 1:\n","      return x\n","  else:\n","      return (\n","          x.unsqueeze(3)\n","          .expand(B, T, n_kv_head, n_rep,\n","                  head_dim)  # Returns a new view of the self tensor with singleton dimensions expanded to a larger size.\n","          .reshape(B, T, n_kv_head * n_rep, head_dim)\n","      )\n","\n","\n","# The attention block:\n","class Attention(nn.Module):\n","    def __init__(self, d_model, n_q_head, n_kv_head, batch_size, seq_len):\n","        super().__init__()\n","        self.head_dim = d_model // n_q_head\n","        self.n_rep = n_q_head // n_kv_head\n","        self.wq = nn.Linear(d_model, self.head_dim * n_q_head, bias=False)\n","        self.wk = nn.Linear(d_model, self.head_dim * n_kv_head, bias=False)\n","        self.wv = nn.Linear(d_model, self.head_dim * n_kv_head, bias=False)\n","        self.wo = nn.Linear(n_q_head * self.head_dim, d_model, bias=False)\n","\n","        self.cache_k = torch.zeros(batch_size, seq_len, n_kv_head, self.head_dim, device=device)\n","        self.cache_v = torch.zeros(batch_size, seq_len, n_kv_head, self.head_dim, device=device)\n","\n","        self.pos_emb = PosEmbedding(seq_len, self.head_dim)\n","\n","    def forward(self, x, attention_mask=None, padding_mask=None, start_pos=None):\n","        B, T, _ = x.shape\n","        xq = self.wq(x)  # [B,T,head_dim * n_q_head]\n","        xk = self.wk(x)  # [B,T,head_dim * n_kv_head]\n","        xv = self.wv(x)  # [B,T,head_dim * n_kv_head]\n","\n","        xq = xq.reshape(B, T, -1, self.head_dim) # [B, T, n_q_head, head_dim]\n","        xk = xk.reshape(B, T, -1, self.head_dim) # [B, T, n_kv_head, head_dim]\n","        xv = xv.reshape(B, T, -1, self.head_dim) # [B, T, n_kv_head, head_dim]\n","\n","        # apply rotary position embedding to query and key\n","        xq = self.pos_emb(xq) # [B, T, n_kv_head, head_dim]\n","        xk = self.pos_emb(xk) # [B, T, n_kv_head, head_dim]\n","\n","        # apply kv-cache during inference\n","        # T is always 1 after prefix\n","        if not self.training:\n","            self.cache_k[:B, start_pos:start_pos + T, :, :] = xk\n","            self.cache_v[:B, start_pos:start_pos + T, :, :] = xv\n","            xk = self.cache_k[:B, :start_pos + T]\n","            xv = self.cache_v[:B, :start_pos + T]\n","\n","        xk = repeat_kv(xk, self.n_rep)\n","        xv = repeat_kv(xv, self.n_rep)\n","\n","        xq = xq.transpose(1, 2)  # [B, n_q_head, T, head_dim]\n","        xk = xk.transpose(1, 2)  # [B, n_q_head, T, head_dim]\n","        xv = xv.transpose(1, 2)  # [B, n_q_head, T, head_dim]\n","\n","        combined_mask = None\n","        # attention mask: [T,T]\n","        if attention_mask is not None:\n","            attention_mask = attention_mask.unsqueeze(0).unsqueeze(0).logical_not()  # [1,1,T,T]\n","            attention_mask = attention_mask.expand(B, xq.shape[1], T, T)\n","            combined_mask = attention_mask\n","        if padding_mask is not None:\n","            padding_mask = padding_mask.unsqueeze(1).unsqueeze(2).logical_not()  # [B,1,1,T]\n","            padding_mask = padding_mask.expand(B, xq.shape[1], T, T)\n","            combined_mask = attention_mask & padding_mask\n","        output = F.scaled_dot_product_attention(xq, xk, xv, attn_mask=combined_mask) # [B, H, T, d // H]\n","\n","        # attention_score = xq @ xk.transpose(2, 3) / math.sqrt(self.head_dim)  # [B,n_q_head,T,T]\n","        # # attention mask: [T,T]\n","        # if attention_mask is not None:\n","        #     attention_mask = attention_mask.unsqueeze(0).unsqueeze(0)  # [1,1,T,T]\n","        #     attention_mask = attention_mask.expand(B, xq.shape[1], T, T)\n","        #     attention_score = attention_score.masked_fill(attention_mask == 1, float('-inf'))\n","        # # padding_mask: [B,T]\n","        # if padding_mask is not None:\n","        #     padding_mask = padding_mask.unsqueeze(1).unsqueeze(2)  # [B,1,1,T]\n","        #     padding_mask = padding_mask.expand(B, xq.shape[1], T, T)\n","        #     attention_score = attention_score.masked_fill(padding_mask == 1, float('-inf'))\n","        # attention_score = F.softmax(attention_score, dim=-1)\n","        # output = attention_score @ xv  # [B,n_q_head,T,head_dim]\n","\n","        output = output.transpose(1, 2).contiguous().reshape(B, T, -1)  # [B,T,d]\n","        return self.wo(output)\n","\n","# Init the decoder block\n","class DecoderBlock(nn.Module):\n","    def __init__(self, d_model, n_q_head, n_kv_head, batch_size, seq_len, hidden_dim):\n","        super().__init__()\n","        self.rms_norm1 = RMSNorm(d_model)\n","        self.attention = Attention(d_model, n_q_head, n_kv_head, batch_size, seq_len)\n","        self.rms_norm2 = RMSNorm(d_model)\n","        self.ffw = FeedForward(d_model, hidden_dim)\n","\n","    def forward(self, x, attention_mask=None, padding_mask=None, start_pos=None):\n","        x = x + self.attention(self.rms_norm1(x), attention_mask, padding_mask, start_pos)\n","        x = x + self.ffw(self.rms_norm2(x))\n","        return x\n","\n","# Combine them together\n","class Llama(nn.Module):\n","    def __init__(self, d_model, n_q_head, n_kv_head, batch_size, seq_len, hidden_dim, vocab_size, n_layers):\n","        super().__init__()\n","        self.embd = WordEmbedding(vocab_size, d_model)\n","        decoder_layer = DecoderBlock(d_model, n_q_head, n_kv_head, batch_size, seq_len, hidden_dim)\n","        self.decoder = nn.ModuleList([decoder_layer for _ in range(n_layers)])\n","        self.rms_norm = RMSNorm(d_model)\n","        self.linear = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, x, attention_mask=None, padding_mask=None, start_pos=None):\n","        x = self.embd(x)\n","        for layer in self.decoder:\n","            x = layer(x, attention_mask, padding_mask, start_pos)\n","        x = self.rms_norm(x)\n","        x = self.linear(x)\n","        return x\n","\n","    def generate(self, context, question, tokenizer):\n","        self.eval()\n","        sequence = '[CON]' + context + '[QUE]' + question + '[ANS]'\n","        seq = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sequence))\n","        ans = seq\n","        start_pos = len(seq)\n","        new_token = None\n","        while new_token != tokenizer.eos_token_id:\n","            if len(ans) > 32: # max_seq_len:\n","                break\n","            input = torch.tensor(seq).unsqueeze(0).to(device)  # [B,T] and B is always 1\n","            # [B,C] since we only need the last token during auto-regression\n","            if input.shape[-1] != 1:\n","                logits = self(input, start_pos=0)[:, -1, :]\n","            else:\n","                logits = self(input, start_pos=start_pos)[:, -1, :]\n","                start_pos += 1\n","            probs = torch.softmax(logits, dim=-1)\n","            output = torch.max(probs, dim=-1)[1]  # [B]\n","            new_token = output.item()\n","            ans = ans + [new_token]\n","            seq = [new_token]\n","        return tokenizer.decode(ans)\n","\n","    # Used to run the bleu score\n","    # def generate_evaluation(self, input, tokenizer):\n","    #     self.eval()\n","    #     seq = input\n","    #     ans = input.tolist()\n","    #     start_pos = len(ans)\n","    #     temp = start_pos\n","    #     new_token = None\n","    #     while new_token != tokenizer.eos_token_id:\n","    #         if len(ans)-temp > 32: # max_seq_len:\n","    #           del input\n","    #           break\n","    #         input = torch.tensor(seq).unsqueeze(0).to(device)  # [B,T] and B is always 1\n","    #         # [B,C] since we only need the last token during auto-regression\n","    #         if input.shape[-1] != 1:\n","    #             logits = self(input, start_pos=0)[:, -1, :]\n","    #         else:\n","    #             logits = self(input, start_pos=start_pos)[:, -1, :]\n","    #             start_pos += 1\n","    #         probs = torch.softmax(logits, dim=-1)\n","    #         output = torch.max(probs, dim=-1)[1]  # [B]\n","    #         new_token = output.item()\n","    #         ans = ans + [new_token]\n","    #         seq = [new_token]\n","    #     return tokenizer.decode(ans)\n","\n","    def generate_evaluation(self, input, tokenizer):\n","      self.eval()\n","      device = next(self.parameters()).device  # Ensures compatibility with the model's device\n","      input = input.to(device)  # Move input tensor to the correct device once\n","\n","      ans = input.tolist()\n","      start_pos = 0\n","      max_len = 32\n","\n","      while True:\n","          # Generate logits for the last position only using cached states if available\n","          logits = self(input, start_pos=start_pos)[:, -1, :]\n","          probs = torch.softmax(logits, dim=-1)\n","          new_token = torch.argmax(probs, dim=-1).item()\n","\n","          if new_token == tokenizer.eos_token_id or len(ans) >= max_len:\n","              break\n","\n","          ans.append(new_token)\n","          new_token_tensor = torch.tensor([[new_token]], dtype=torch.long, device=device)\n","          input = torch.cat([input, new_token_tensor], dim=1)  # Efficiently expand input\n","          start_pos += 1  # Move start position forward for kv-cache\n","      return tokenizer.decode(ans)\n","\n","\n","\n","\n","\n","def build_model(d_model, nhead, dim_feedforward, num_layers, vocab_size, max_seq_len,\n","                n_q_head, n_kv_head, batch_size):\n","\n","    model = Llama(d_model, n_q_head, n_kv_head, batch_size, max_seq_len, dim_feedforward, vocab_size, num_layers)\n","\n","    def initialize_weights(m):\n","        if isinstance(m, nn.Linear):\n","            # Apply Xavier initialization for Linear layers\n","            nn.init.xavier_uniform_(m.weight)\n","            if m.bias is not None:\n","                nn.init.constant_(m.bias, 0)\n","        elif isinstance(m, nn.Embedding):\n","            # Apply Xavier initialization for Embedding layers\n","            nn.init.xavier_uniform_(m.weight)\n","    model.apply(initialize_weights)\n","\n","    return model\n"],"metadata":{"id":"UDYQOJxF8HNZ","executionInfo":{"status":"ok","timestamp":1723249989495,"user_tz":240,"elapsed":110403,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["# Train Process"],"metadata":{"id":"F0LeSFmd48Dd"}},{"cell_type":"markdown","source":["### Init the model"],"metadata":{"id":"o40kO-VC157n"}},{"cell_type":"code","source":["# Save checkpoint function\n","def save_checkpoint(model, optimizer, scheduler, epoch, path):\n","    checkpoint = {\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'scheduler_state_dict': scheduler.state_dict(),\n","        'epoch': epoch\n","    }\n","    torch.save(checkpoint, path)\n","\n","# Load checkpoint function\n","def load_checkpoint(model, optimizer, scheduler, path):\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","    epoch = checkpoint['epoch']\n","    return model, optimizer, scheduler, epoch\n","\n","# Init the model\n","model = build_model(MASTER_CONFIG['d_model'], MASTER_CONFIG['nhead'], MASTER_CONFIG['dim_feedforward'],\n","                    MASTER_CONFIG['num_layers'], MASTER_CONFIG['vocab_size'], MASTER_CONFIG['max_seq_len'], MASTER_CONFIG['n_q_head'],\n","                    MASTER_CONFIG['n_kv_head'], MASTER_CONFIG['batch_size'])\n","\n","print('Number of parameters in this model: ', np.sum([p.numel() for p in model.parameters()]))\n","print('device: ', device)\n","# Send the model to GPU\n","model = model.to(device)\n","# Mix precision training\n","torch.set_float32_matmul_precision('high')\n","# Other optimize method\n","model = torch.compile(model)\n","\n","optimizer = AdamW(model.parameters(), lr=MASTER_CONFIG['learning_rate'], fused=True)\n","scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=MASTER_CONFIG['num_epochs'])\n","scaler = GradScaler()\n","# loss_fn = Loss()\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxTm6F4617gr","executionInfo":{"status":"ok","timestamp":1723250009829,"user_tz":240,"elapsed":2514,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"outputId":"1b9a0fe6-ee8e-47f0-c8f0-15361c2fbc48"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of parameters in this model:  150513536\n","device:  cuda\n"]}]},{"cell_type":"markdown","source":["### Load the model"],"metadata":{"id":"acUIlP__19KC"}},{"cell_type":"code","source":["try:\n","    # Attempt to load the checkpoint\n","    model, optimizer, scheduler, start_epoch = load_checkpoint(model, optimizer, scheduler, path=llama_path)\n","except Exception as e:\n","    # If an error occurs, print the error and continue\n","    print(f\"Failed to load checkpoint from {llama_path}: {e}\")\n","    # Optionally, set start_epoch to 0\n","    start_epoch = 0"],"metadata":{"id":"5eW9uOd01_zf","executionInfo":{"status":"ok","timestamp":1723248449420,"user_tz":240,"elapsed":24525,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Training the model"],"metadata":{"id":"Hipv-Gn22Bjy"}},{"cell_type":"code","source":["\n","# lossi = []\n","# count = 0\n","\n","# for epoch in tqdm(range(start_epoch, MASTER_CONFIG['num_epochs']), desc='epoch'):\n","#     for batch in tqdm(dataloader_train, desc='training batch'):\n","#         model.train()\n","#         optimizer.zero_grad()\n","\n","#         start = time.time()\n","#         input = batch['input'].to(device)\n","#         target = batch['output'].to(device)\n","#         attention_mask = batch['attention_mask'].to(device)\n","#         padding_mask = batch['padding_mask'].to(device)\n","#         with autocast():\n","#             predict = model(input, attention_mask, padding_mask)\n","#             loss = loss_fn(predict.transpose(1, 2), target)\n","\n","#         scaler.scale(loss).backward()\n","#         scaler.unscale_(optimizer)\n","#         norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","#         scaler.step(optimizer)\n","#         scaler.update()\n","\n","#         # loss.backward()\n","#         # norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","#         # optimizer.step()\n","\n","#         torch.cuda.synchronize()\n","\n","#         end = time.time()\n","#         dt = (end-start)*1000\n","\n","#         if count % 300 == 0:\n","#             print(f'loss: {loss.item():.4f}', f'time: {dt:.2f}ms', f'gradient norm: {norm.item():.3f}')\n","#             lossi.append(loss.item())\n","#             context = \"US national day is July 4th.\"\n","#             question = 'When is US national day?'\n","#             model.eval()\n","#             with torch.no_grad():\n","#                 result = model.generate(context, question, tokenizer)\n","#             print(result)\n","#         count += 1\n","#     if (epoch+1) % 3 == 0 and epoch != 0:\n","#       save_checkpoint(model, optimizer, scheduler, epoch, llama_path)\n","\n","#     scheduler.step()\n","\n","# np.save(r'training_loss.npy', np.array(lossi))\n","# plt.figure()\n","# plt.plot(range(len(lossi)), lossi, label='loss', marker='o')\n","# plt.xlabel('training process')\n","# plt.ylabel('loss')\n","# plt.title('loss over training process')\n","# plt.legend()\n","# plt.grid(True)\n","# plt.show()"],"metadata":{"id":"5grbDPND2D1D","executionInfo":{"status":"ok","timestamp":1723248449421,"user_tz":240,"elapsed":17,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"CbQM-jEM2HaX"}},{"cell_type":"code","source":["# prediction = []\n","# target = []\n","\n","# for batch in tqdm(dataloader_val, desc='testing batch'):\n","#   # Find the index of the target number\n","#   indices = torch.nonzero(batch['input'] == 30526)\n","#   if indices.nelement() == 0:\n","#       print(\"Target number not found in the tensor.\")\n","#   else:\n","#       # Get the first occurrence if there are multiple\n","#       target_index = indices[0, 1]  # indices[0, 1] because the shape is [B, T] and B=1\n","\n","#       # Slice the tensor to include elements up to and including the target index\n","#       input = batch['input'][:, :target_index + 1]\n","\n","#   pred = model.generate_evaluation(input = input.squeeze(0), tokenizer = tokenizer)\n","#   prediction.append(pred)\n","\n","#   # Find the index of the target number\n","#   indices = torch.nonzero(batch['output'] == 30526)\n","#   if indices.nelement() == 0:\n","#       print(\"Target number not found in the tensor.\")\n","#   else:\n","#       # Get the first occurrence if there are multiple\n","#       target_index = indices[0, 1]  # indices[0, 1] because the shape is [B, T] and B=1\n","\n","#       # Slice the tensor to include elements up to and including the target index\n","#       output = batch['output'][:, target_index:-1]\n","\n","#   target.append([tokenizer.decode(output[0].tolist())])\n","#   break\n","\n","# bleu = evaluate.load(\"bleu\")\n","# results = bleu.compute(predictions=prediction, references=target)\n","# print(results)"],"metadata":{"id":"wWd8rmG9VkVP","executionInfo":{"status":"ok","timestamp":1723248449421,"user_tz":240,"elapsed":3,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["prediction = []\n","target = []\n","def extract_until_token(tensor, token_id):\n","    indices = torch.nonzero(tensor == token_id, as_tuple=False)\n","    # Get the first occurrence if there are multiple\n","    target_index = indices[0, 1]  # indices[0, 1] because the shape is [B, T] and B=1\n","\n","    # Slice the tensor to include elements up to and including the target index\n","    output_tensor = tensor[:, :target_index + 1]\n","    return output_tensor\n","\n","def extract_after_token(tensor, token_id):\n","    indices = torch.nonzero(tensor == token_id, as_tuple=False)\n","    # Get the first occurrence if there are multiple\n","    target_index = indices[0, 1]  # indices[0, 1] because the shape is [B, T] and B=1\n","\n","    # Slice the tensor to include elements up to and including the target index\n","    output_tensor = tensor[:, target_index+1:]\n","    return output_tensor\n","\n","for batch in tqdm(dataloader_val, desc='testing batch'):\n","    input_tensor = extract_until_token(batch['input'], 30526)\n","    output_tensor = extract_after_token(batch['output'], 30526)\n","\n","    pred = model.generate_evaluation(input=input_tensor, tokenizer=tokenizer)\n","    prediction.append(pred)\n","    target.append([tokenizer.decode(output_tensor.tolist())])\n","    break\n","# bleu = evaluate.load(\"bleu\")\n","# results = bleu.compute(predictions=prediction, references=target)\n","# print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388,"referenced_widgets":["ea6d704c7c0d45e7b3aa0b39fd35fba5","bc6fd998c9114c23a051d8979798ad61","58a68fa066f741efbf38a9345cf6f1d2","10ca9f8d6a114d78a04022db9a3ec12b","85434f0f9bc2487ea4e0654c583bbca4","d194426bdd7c4cd08540ae820b6e5829","3451ee7fa4c7477aa544974504cd8952","1eca2ff49ec246f5a003dfacbff4bee0","82c02d1f864242f2b7f892df0ef1e03c","7ca55b325b2c49849ffba44bcfbefa25","b78a9bae978142108aa5393c3c823990"]},"id":"nSALwBT_mGXG","executionInfo":{"status":"error","timestamp":1723250014911,"user_tz":240,"elapsed":605,"user":{"displayName":"Jiayuan Shen","userId":"13054373677089839651"}},"outputId":"4bb016fc-1f90-4db8-970a-4969cce5effe"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["testing batch:   0%|          | 0/9800 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea6d704c7c0d45e7b3aa0b39fd35fba5"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for +: 'NoneType' and 'int'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-5c431d1bff4e>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_after_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30526\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-f88e5d77df81>\u001b[0m in \u001b[0;36mgenerate_evaluation\u001b[0;34m(self, input, tokenizer)\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m           \u001b[0;31m# Generate logits for the last token in the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m           \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m           \u001b[0mnew_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-f88e5d77df81>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask, padding_mask, start_pos)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-f88e5d77df81>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask, padding_mask, start_pos)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-f88e5d77df81>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask, padding_mask, start_pos)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# T is always 1 after prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mstart_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"]}]}]}